{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Global hyperparameters\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Flatten and rescale the images\n",
    "x_train = x_train.reshape(60000, 784).astype('float32')\n",
    "x_test = x_test.reshape(10000, 784).astype('float32')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 2s 45us/step - loss: 0.4792 - acc: 0.8601 - val_loss: 0.2295 - val_acc: 0.9347\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 0.2611 - acc: 0.9236 - val_loss: 0.1949 - val_acc: 0.9443\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 0.2191 - acc: 0.9359 - val_loss: 0.1670 - val_acc: 0.9523\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1893 - acc: 0.9450 - val_loss: 0.1608 - val_acc: 0.9528\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 0.1722 - acc: 0.9496 - val_loss: 0.1372 - val_acc: 0.9607\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1576 - acc: 0.9534 - val_loss: 0.1407 - val_acc: 0.9602\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 2s 41us/step - loss: 0.1498 - acc: 0.9550 - val_loss: 0.1360 - val_acc: 0.9618\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1414 - acc: 0.9577 - val_loss: 0.1436 - val_acc: 0.9565\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1345 - acc: 0.9596 - val_loss: 0.1374 - val_acc: 0.9612\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1294 - acc: 0.9611 - val_loss: 0.1273 - val_acc: 0.9630\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1248 - acc: 0.9623 - val_loss: 0.1297 - val_acc: 0.9645\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1209 - acc: 0.9628 - val_loss: 0.1289 - val_acc: 0.9633\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1169 - acc: 0.9649 - val_loss: 0.1449 - val_acc: 0.9613\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1140 - acc: 0.9653 - val_loss: 0.1284 - val_acc: 0.9652\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1106 - acc: 0.9665 - val_loss: 0.1345 - val_acc: 0.9613\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1088 - acc: 0.9672 - val_loss: 0.1286 - val_acc: 0.9648\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1056 - acc: 0.9681 - val_loss: 0.1309 - val_acc: 0.9640\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1027 - acc: 0.9690 - val_loss: 0.1365 - val_acc: 0.9615\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1022 - acc: 0.9698 - val_loss: 0.1274 - val_acc: 0.9662\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 2s 40us/step - loss: 0.1002 - acc: 0.9689 - val_loss: 0.1317 - val_acc: 0.9623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
